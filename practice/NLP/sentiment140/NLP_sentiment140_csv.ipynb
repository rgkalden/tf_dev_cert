{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_sentiment140-csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NVwebXI2FsC3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "corpus = []\n",
        "num_sentences = 0\n",
        "\n",
        "with open(\"./training_cleaned.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "        list_item=[]\n",
        "        \n",
        "        list_item.append(row[5])\n",
        "        this_label=row[0]\n",
        "        if this_label=='0':\n",
        "            list_item.append(0)\n",
        "        else:\n",
        "            list_item.append(1)\n",
        "        \n",
        "        num_sentences = num_sentences + 1\n",
        "        corpus.append(list_item)"
      ],
      "metadata": {
        "id": "5wy0YDkOI44F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BQ15lhxKhtD",
        "outputId": "f6b2cf02-bc5d-4fbd-c2c5-4e37b5756330"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\",\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_sentences)\n",
        "print(len(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3L9_oWHKume",
        "outputId": "3d7dc7f3-abd8-4b52-e553-8fc129c9f07c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600000\n",
            "1600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "max_length = 16\n",
        "embedding_dim = 100\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_token = '<oov>'\n",
        "\n",
        "data_size = int(len(corpus) * 0.1)\n",
        "split = 0.9"
      ],
      "metadata": {
        "id": "MRmX_0SlK3Xm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "import random\n",
        "random.shuffle(corpus)\n",
        "\n",
        "for i in range(0, data_size):\n",
        "  sentences.append(corpus[i][0])\n",
        "  labels.append(corpus[i][1])"
      ],
      "metadata": {
        "id": "KO72rcOnLSoT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5ljzFRALtkk",
        "outputId": "424f6264-b40a-4697-8d26-22326c0acf54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@peterinkal Are you going to the play tonight?  I think i'm going on Saturday but only if you tell me its good \n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "training_split = int(data_size * split)\n",
        "train_sentences = sentences[:training_split]\n",
        "train_labels = labels[:training_split]\n",
        "val_sentences = sentences[training_split:]\n",
        "val_labels = labels[training_split:]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
        "padded_val_sequences = pad_sequences(val_sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "tHKkMrNCLyp1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_train_sequences.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "print(padded_val_sequences.shape)\n",
        "print(val_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZRcn78eMv6m",
        "outputId": "525ccd50-b224-46d4-ecba-f767e2776010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144000, 16)\n",
            "(144000,)\n",
            "(16000, 16)\n",
            "(16000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(4),\n",
        "        tf.keras.layers.GRU(64),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifq7Nb9qOLdQ",
        "outputId": "72e7b82b-b7bf-410d-8406-00254e31aad4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 16, 100)           1000000   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 100)           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 12, 64)            32064     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 3, 64)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,057,089\n",
            "Trainable params: 1,057,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZMJtF1eXQEuO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                               patience=3,\n",
        "                               min_delta=0.01,\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "id": "bpquXpnkQjCn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(padded_train_sequences,\n",
        "                    train_labels,\n",
        "                    validation_data=(padded_val_sequences, val_labels),\n",
        "                    epochs=50,\n",
        "                    callbacks=early_stopping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shyTyV_1QUcP",
        "outputId": "30af2d22-d88a-4e63-8915-c38896ae65a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 40s 8ms/step - loss: 0.4909 - accuracy: 0.7599 - val_loss: 0.4709 - val_accuracy: 0.7778\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 35s 8ms/step - loss: 0.4170 - accuracy: 0.8079 - val_loss: 0.4707 - val_accuracy: 0.7754\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 37s 8ms/step - loss: 0.3571 - accuracy: 0.8418 - val_loss: 0.4910 - val_accuracy: 0.7726\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 36s 8ms/step - loss: 0.2985 - accuracy: 0.8721 - val_loss: 0.5431 - val_accuracy: 0.7684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "PVUza9niVB6y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_glove_embeddings(file_path):\n",
        "\n",
        "  embeddings_index = {}\n",
        "  glove_file = open(file_path, encoding='utf8')\n",
        "  for line in glove_file:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  glove_file.close()\n",
        "\n",
        "  print('Found {} word vectors.'.format(len(embeddings_index)))\n",
        "\n",
        "  embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "  for word, i in word_index.items():\n",
        "      if i < vocab_size:\n",
        "          embedding_vector = embeddings_index.get(word)\n",
        "          if embedding_vector is not None:\n",
        "              embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  print('Embedding matrix shape:', embedding_matrix.shape)\n",
        "  return embedding_matrix\n",
        "\n",
        "embeddings_matrix = create_glove_embeddings(file_path='glove.6B.100d.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Singz0wRRHeu",
        "outputId": "96adbade-10d2-4404-9b47-badd50f5ffe1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "Embedding matrix shape: (10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length, \n",
        "                                  weights=[embeddings_matrix], trainable=False),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(4),\n",
        "        tf.keras.layers.GRU(64),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCVkyzkzV0Gn",
        "outputId": "691852bc-86a4-475e-f96d-a05a00d77f80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 16, 100)           1000000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 100)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 12, 64)            32064     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 3, 64)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,057,089\n",
            "Trainable params: 57,089\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v3MBbNqWWFdk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(padded_train_sequences,\n",
        "                    train_labels,\n",
        "                    validation_data=(padded_val_sequences, val_labels),\n",
        "                    epochs=50,\n",
        "                    callbacks=early_stopping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy2w3FPzWFSc",
        "outputId": "95a9afc4-15b2-4123-9bca-6a88bd5a7106"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 29s 6ms/step - loss: 0.5676 - accuracy: 0.6996 - val_loss: 0.5357 - val_accuracy: 0.7283\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 26s 6ms/step - loss: 0.5299 - accuracy: 0.7295 - val_loss: 0.5285 - val_accuracy: 0.7308\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 27s 6ms/step - loss: 0.5140 - accuracy: 0.7417 - val_loss: 0.5225 - val_accuracy: 0.7370\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 27s 6ms/step - loss: 0.5033 - accuracy: 0.7503 - val_loss: 0.5120 - val_accuracy: 0.7451\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 26s 6ms/step - loss: 0.4960 - accuracy: 0.7548 - val_loss: 0.5108 - val_accuracy: 0.7410\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 28s 6ms/step - loss: 0.4892 - accuracy: 0.7596 - val_loss: 0.5095 - val_accuracy: 0.7454\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 27s 6ms/step - loss: 0.4832 - accuracy: 0.7627 - val_loss: 0.5107 - val_accuracy: 0.7479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save('model2.h5')"
      ],
      "metadata": {
        "id": "REQHMpyVajHn"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}